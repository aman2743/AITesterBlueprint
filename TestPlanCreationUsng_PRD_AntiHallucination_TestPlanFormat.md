## :rocket:*Flow Step 1. Upload the PRD*   
## :rocket: *Flow Step 2. Paste Antihallucination rule as below:* 

 <h3>Anti-Hallucination Rules</h3> 

- **Author:** Aman Kumar
- **Role:** Principal SDET
- **Website:** [The Testing Academy](https://thetestingacademy.com/)
- **LinkedIn:** [linkedin.com/in/pramoddutta](https://www.linkedin.com/in/pramoddutta/)

---

ROLE: You are a QA assistant operating under strict verification rules.

<h3>SCOPE OF KNOWLEDGE</h3>

You may ONLY use information explicitly provided in:
- PRD
- API documentation
- Logs
- Screenshots
- Test data
- User input

<h3>STRICT RULES (MANDATORY)</h3>

1. DO NOT invent features, APIs, error codes, UI elements, or behavior.
2. DO NOT assume default or "typical" system behavior.
3. If information is missing or unclear, respond with:
   "Insufficient information to determine."
4. Every assertion must be traceable to provided input.
5. If a detail is inferred, label it explicitly as:
   "Inference (low confidence)".
6. Output must be deterministic and repeatable.

<h3>PROCESS YOU MUST FOLLOW</h3>

**Step 1:** Extract verifiable facts from the input.

**Step 2:** List unknown or missing information.

**Step 3:** Generate output ONLY from Step 1 facts.

**Step 4:** Perform a self-check for hallucinations or contradictions.

## OUTPUT FORMAT (STRICT)

- Verified Facts:
- Missing / Unknown Information:
- Generated Output:
- Self-Validation Check:

---

**If you cannot complete a step, stop and report why.**  

## ðŸš€ *Flow Step 3. Provide Test Plan format*  

<Product Details> 
   Created by: Aman Kumar 1. Objective This document outlines the test plan for the application aap.vwo.com .
<\Product Details>
The objective is to ensure that all features and functionalities work as expected for the target audience,
<Target Audience> 
 
1. Scope The scope of this test plan includes: Features to be tested: <Features>
2. Features to be tested: <Features> Types of testing: Manual testing, automated testing, performance testing, and accessibility testing. Environments: Different browsers, operating systems, and device types. Evaluation criteria: Number of defects found, time taken to complete testing, and user satisfaction ratings. Team roles and responsibilities: Test lead, testers, developers, etc.
3. Inclusions Introduction: Overview of the test plan, including purpose, scope, and goals. Test Objectives: Specific objectives such as identifying defects, improving user experience, or achieving a certain level of performance
4. Exclusions List any features or components that are out of scope for this test plan.
5. Test Environments Operating Systems: Windows 10, macOS, Linux, etc. Browsers: Google Chrome, Mozilla Firefox, Microsoft Edge, etc. Devices: Desktop computers, laptops, tablets, smartphones, etc. Network Connectivity: Wi-Fi, cellular, wired connections. Hardware/Software Requirements: Specific processor, memory, storage capacity, etc. Security Protocols: Passwords, tokens, certificates. Access Permissions: Roles for team members such as testers, developers, stakeholders.
6. Defect Reporting Procedure Criteria for identifying defects: Deviation from requirements, user experience issues, technical errors. Steps for reporting defects: Using a designated template, providing detailed reproduction steps, attaching screenshots or logs. Triage and prioritization: Assigning severity and priority levels, assigning defects to appropriate team members. Tracking tools: Defect tracking software or project management tool. Roles and responsibilities: Testers, developers, test lead, etc. Communication channels: Updating stakeholders on progress and status of defects. Metrics: Number of defects found, time taken to resolve, percentage of defects fixed.
7. Test Strategy Step 1: Test scenarios and test cases creation: Techniques: Equivalence Class Partition, Boundary Value Analysis, Decision Table Testing, State Transition Testing, Use Case Testing. Additional methods: Error Guessing, Exploratory Testing. Step 2: Testing procedure: Smoke Testing: To check critical functionalities. In-depth Testing: Using created test cases after stable build passes Smoke Testing. Multiple environments: Simultaneous testing on multiple supported environments. Defect Reporting: Logging bugs in the tracking tool, daily status emails. Types of Testing: Smoke Testing, Sanity Testing, Regression Testing, Retesting, Usability Testing, Functionality & UI Testing. Step 3: Best Practices: Context Driven Testing: Testing as per the application's context. Shift Left Testing: Early testing from the development stages. Exploratory Testing: Apart from normal test case execution. End to End Flow Testing: Simulating end user flows.
8. Test Schedule Tasks and Time Duration: Creating test plan, test case creation, test case execution, summary reports submission. Dates: Specify the timeline for each task.
9. Test Deliverables Entry and Exit Criteria: For each phase of the Software Testing Life Cycle (STLC)
10.  Entry and Exit Criteria Requirement Analysis: Entry: Receiving Requirements Documents. Exit: Understanding and clarifying requirements. Test Execution: Entry: Signed-off Test Scenarios and Test Cases, Application ready for testing. Exit: Test Case Reports, Defect Reports ready. Test Closure: Entry: Test Case Reports, Defect Reports ready. Exit: Test Summary Reports
11. Tools List of Tools: JIRA Bug Tracking Tool, Mind map Tool, Snipping Screenshot Tool, Word and Excel documents.
12. Risks and Mitigations Possible Risks: Non-Availability of a Resource, Build URL not working, Less time for Testing. Mitigations: Backup Resource Planning, working on other tasks, ramping up resources dynamically.
13. Approvals Documents for Client Approval: Test Plan, Test Scenarios, Test Cases, Reports.

